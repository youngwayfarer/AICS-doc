{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3876ddc",
   "metadata": {},
   "source": [
    "# matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "\n",
    "# The size of the matrix\n",
    "# (M, K) x (K, N)\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "dtype = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc12d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "target = tvm.target.Target(target=\"llvm\", host=\"llvm\")\n",
    "dev = tvm.device(target.kind.name, 0)\n",
    "\n",
    "a = tvm.runtime.tensor(np.random.rand(M, K).astype(dtype), dev)\n",
    "b = tvm.runtime.tensor(np.random.rand(K, N).astype(dtype), dev)\n",
    "\n",
    "np_repeat = 100\n",
    "np_running_time = timeit.timeit(\n",
    "    setup=\"import numpy as np\\n\"\n",
    "    \"M = \" + str(M) + \"\\n\"\n",
    "    \"K = \" + str(K) + \"\\n\"\n",
    "    \"N = \" + str(N) + \"\\n\"\n",
    "    'dtype = \"float32\"\\n'\n",
    "    \"a = np.random.rand(M, K).astype(dtype)\\n\"\n",
    "    \"b = np.random.rand(K, N).astype(dtype)\\n\",\n",
    "    stmt=\"answer = np.dot(a, b)\",\n",
    "    number=np_repeat,\n",
    ")\n",
    "print(\"np running time: %f\" % (np_running_time / np_repeat))\n",
    "\n",
    "answer = np.dot(a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0d6c6",
   "metadata": {},
   "source": [
    "# TVM Matrix Multiplication using TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "k = te.reduce_axis((0, K), \"k\")\n",
    "A = te.placeholder((M, K), name=\"A\")\n",
    "B = te.placeholder((K, N), name=\"B\")\n",
    "C: Any = te.compute((M, N), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name=\"C\")\n",
    "\n",
    "prin_func = te.create_prim_func([A, B, C]).with_attr(\"global_symbol\", \"mmult\")\n",
    "mod = tvm.IRModule({\"mmult\": prin_func})\n",
    "lib = tvm.build(mod, target=target)\n",
    "func = lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_operation(lib, optimization, log):\n",
    "    func = lib[\"mmult\"]\n",
    "    assert func\n",
    "\n",
    "    c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "    func(a, b, c)\n",
    "    tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "    evaluator = lib.time_evaluator(lib.entry_name, dev, number=10)\n",
    "    mean_time = evaluator(a, b, c).mean\n",
    "    print(\"%s: %f\" % (optimization, mean_time))\n",
    "    log.append((optimization, mean_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81432bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "\n",
    "evaluate_operation(lib, \"none\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf376e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca739d",
   "metadata": {},
   "source": [
    "# Optimization 1: Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = 32\n",
    "\n",
    "sch = tvm.tir.Schedule(mod)\n",
    "block_c = sch.get_block(\"C\", func_name=\"mmult\")\n",
    "x, y, k = sch.get_loops(block_c)\n",
    "\n",
    "xo, xi = sch.split(x, factors=[None, bn])\n",
    "yo, yi = sch.split(y, factors=[None, bn])\n",
    "ko, ki = sch.split(k, factors = [None, 4])\n",
    "\n",
    "sch.reorder(xo, yo, ko, ki, xi, yi)\n",
    "\n",
    "blocked_mod = sch.mod\n",
    "blocked_lib = tvm.build(blocked_mod, target=target)\n",
    "\n",
    "func = blocked_lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b957541",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(blocked_lib, \"blocking\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda96a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocked_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c9810",
   "metadata": {},
   "source": [
    "# Optimization 2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09934110",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch.vectorize(yi)\n",
    "\n",
    "vectorized_mod = sch.mod\n",
    "vectorized_lib = tvm.build(vectorized_mod, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(vectorized_lib, \"vectorization\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef86def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorized_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d826482",
   "metadata": {},
   "source": [
    "# Optimization 3: Loop Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = tvm.tir.Schedule(mod)\n",
    "block_c = sch.get_block(\"C\", func_name=\"mmult\")\n",
    "x, y, k = sch.get_loops(block_c)\n",
    "\n",
    "xo, xi = sch.split(x, factors=[None, bn])\n",
    "yo, yi = sch.split(y, factors=[None, bn])\n",
    "ko, ki = sch.split(k, factors = [None, 4])\n",
    "\n",
    "sch.reorder(xo, yo, ko, xi, ki, yi)\n",
    "sch.vectorize(yi)\n",
    "\n",
    "permuted_mod = sch.mod\n",
    "permuted_lib = tvm.build(permuted_mod, target=target)\n",
    "\n",
    "func = permuted_lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951715e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(permuted_lib, \"loop permutation\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(permuted_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679eac69",
   "metadata": {},
   "source": [
    "# Optimization 4: Array Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = te.reduce_axis((0, K), \"k\")\n",
    "\n",
    "packedB = te.compute((N // bn, K, bn), lambda x, y, z: B[y, x * bn + z], name=\"packedB\")\n",
    "C: Any = te.compute(\n",
    "    (M, N),\n",
    "    lambda x, y: te.sum(A[x, k] * packedB[tvm.tir.floordiv(y, bn), k, tvm.tir.indexmod(y, bn)], axis=k),\n",
    "    name=\"C\",\n",
    ")\n",
    "\n",
    "prim_func = te.create_prim_func([A, B, C]).with_attr(\"global_symbol\", \"mmult\")\n",
    "mod = tvm.IRModule({\"mmult\": prim_func})\n",
    "\n",
    "sch = tvm.tir.Schedule(mod)\n",
    "\n",
    "block_c = sch.get_block(\"C\", func_name=\"mmult\")\n",
    "x, y, k = sch.get_loops(block_c)\n",
    "xo, xi = sch.split(x, factors=[None, bn])\n",
    "yo, yi = sch.split(y, factors=[None, bn])\n",
    "ko, ki = sch.split(k, factors=[None, 4])\n",
    "\n",
    "sch.reorder(xo, yo, ko, xi, ki, yi)\n",
    "sch.vectorize(yi)\n",
    "\n",
    "block_pack = sch.get_block(\"packedB\", func_name=\"mmult\")\n",
    "xp, yp, zp = sch.get_loops(block_pack)\n",
    "sch.vectorize(zp)\n",
    "sch.parallel(xp)\n",
    "\n",
    "packing_mod = sch.mod\n",
    "packing_lib = tvm.build(packing_mod, target=target)\n",
    "\n",
    "func = packing_lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(packing_lib, \"array packing\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df979bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(packing_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1259c9a",
   "metadata": {},
   "source": [
    "# Optimization 5: Optimizing Block Writing Through Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = tvm.tir.Schedule(mod)\n",
    "\n",
    "block_c = sch.get_block(\"C\", func_name=\"mmult\")\n",
    "x, y, k = sch.get_loops(block_c)\n",
    "\n",
    "CC = sch.cache_write(block_c, 0, \"global\")\n",
    "\n",
    "xo, xi = sch.split(x, factors=[None, bn])\n",
    "yo, yi = sch.split(y, factors=[None, bn])\n",
    "ko, ki = sch.split(k, factors=[None, 4])\n",
    "sch.reorder(xo, yo, ko, xi, ki, yi)\n",
    "\n",
    "xc, yc = sch.get_loops(CC)[-2:]\n",
    "sch.unroll(ki)\n",
    "sch.vectorize(yc)\n",
    "\n",
    "sch.reverse_compute_at(CC, yo)\n",
    "\n",
    "write_cache_mod = sch.mod\n",
    "write_cache_lib = tvm.build(write_cache_mod, target=target)\n",
    "\n",
    "func = write_cache_lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(write_cache_lib, \"write cache\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564509fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(write_cache_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e872d8",
   "metadata": {},
   "source": [
    "# Optimization 6: Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_c = sch.get_block(\"C\", \"mmult\")\n",
    "xo = sch.get_loops(block_c)[0]\n",
    "sch.parallel(xo)\n",
    "\n",
    "block_pack = sch.get_block(\"packedB\", \"mmult\")\n",
    "xp, yp, zp = sch.get_loops(block_pack)\n",
    "sch.parallel(xp)\n",
    "sch.vectorize(zp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b006a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelization_mod = sch.mod\n",
    "parallelization_lib = tvm.build(parallelization_mod, target=target)\n",
    "\n",
    "func = parallelization_lib[\"mmult\"]\n",
    "\n",
    "c = tvm.runtime.tensor(np.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bca62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_operation(parallelization_lib, \"write cache\", log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb62a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parallelization_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d4897",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = log[0][1]\n",
    "print(\"%s\\t%s\\t%s\" % (\"Operator\".rjust(20), \"Timing\".rjust(20), \"Performance\".rjust(20)))\n",
    "for result in log:\n",
    "    print(\n",
    "        \"%s\\t%s\\t%s\"\n",
    "        % (result[0].rjust(20), str(result[1]).rjust(20), str(result[1] / baseline).rjust(20))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICS-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
